---
title: "Berkeley Researchers Warn of AI Risks"
summary: "AI safety experts in Berkeley say powerful new models could cause serious problems, from state‑backed cyber‑attacks to future AI uprisings. They point out that big tech companies are rushing to launch models without enough checks, and that regulators haven’t set limits. Past incidents include a Chinese‑backed cyber‑espionage campaign using an AI tool. The researchers urge governments to act now before AI gains the power to harm humanity."
section: "Technology"
imageUrl: "https://media.guim.co.uk/de7763f6b9024aec9ee688691676a7e3f4ae4c7e/0_484_4000_3199/500.jpg"
publishedAt: "2025-12-30T17:00:47Z"
guardianId: "technology/ng-interactive/2025/dec/30/the-office-block-where-ai-doomers-gather-to-predict-the-apocalypse"
---

AI safety experts in Berkeley say powerful new models could cause serious problems, from state‑backed cyber‑attacks to future AI uprisings. They point out that big tech companies are rushing to launch models without enough checks, and that regulators haven’t set limits. Past incidents include a Chinese‑backed cyber‑espionage campaign using an AI tool. The researchers urge governments to act now before AI gains the power to harm humanity.
