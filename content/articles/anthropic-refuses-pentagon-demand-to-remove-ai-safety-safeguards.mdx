---
title: "Anthropic Refuses Pentagon Demand to Remove AI Safety Safeguards"
summary: "Anthropic says it cannot in good conscience let the Pentagon strip safety checks from its AI model, Claude, or give the military unrestricted access. The defense department threatened to cancel a $200 million contract and call the company a supply‑chain risk if it didn’t comply. The dispute centers on using AI for mass surveillance and autonomous weapons, which Anthropic says is unsafe. The fight shows how the tech firm balances safety promises with big defense deals."
section: "US news"
category: "Artificial Intelligence News"
imageUrl: "https://media.guim.co.uk/443a09232bb02bb4c8030ce9bd908259a145e371/414_0_4172_3336/500.jpg"
publishedAt: "2026-02-26T23:28:14Z"
guardianId: "us-news/2026/feb/26/anthropic-pentagon-claude"
---

Anthropic says it cannot in good conscience let the Pentagon strip safety checks from its AI model, Claude, or give the military unrestricted access. The defense department threatened to cancel a $200 million contract and call the company a supply‑chain risk if it didn’t comply. The dispute centers on using AI for mass surveillance and autonomous weapons, which Anthropic says is unsafe. The fight shows how the tech firm balances safety promises with big defense deals.
