---
title: "AI expert pushes back predicted danger of AI"
summary: "Daniel Kokotajlo, a former OpenAI employee, had warned in 2024 that by 2027 AI could code on its own, become super‑intelligent, and eventually kill humans. In a new update he says that full‑autonomous coding will likely arrive in the early 2030s, with super‑intelligence around 2034, and he no longer predicts a 2030 doomsday. Other experts say the danger is still far away and the term AGI is getting fuzzy."
section: "Technology"
imageUrl: "https://media.guim.co.uk/621d2774578bd82f788e889462ab440458846efd/847_0_4751_3800/500.jpg"
publishedAt: "2026-01-06T06:00:29Z"
guardianId: "technology/2026/jan/06/leading-ai-expert-delays-timeline-possible-destruction-humanity"
---

Daniel Kokotajlo, a former OpenAI employee, had warned in 2024 that by 2027 AI could code on its own, become super‑intelligent, and eventually kill humans. In a new update he says that full‑autonomous coding will likely arrive in the early 2030s, with super‑intelligence around 2034, and he no longer predicts a 2030 doomsday. Other experts say the danger is still far away and the term AGI is getting fuzzy.
