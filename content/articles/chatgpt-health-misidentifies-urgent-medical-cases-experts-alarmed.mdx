---
title: "ChatGPT Health Misidentifies Urgent Medical Cases, Experts Alarmed"
summary: "A recent study found that ChatGPT Health often misses medical emergencies, giving dangerous advice. Researchers tested 60 real‑world scenarios and discovered that over half the cases needing urgent care were mis‑triaged. The AI also failed to flag suicidal thoughts in some tests. Experts warn that this could harm users and call for stronger safety rules and independent reviews."
section: "Technology"
category: "Artificial Intelligence News"
imageUrl: "https://media.guim.co.uk/3e8651062ef84e39193ac5df7c3ef7a576210509/588_0_3626_2901/500.jpg"
publishedAt: "2026-02-26T14:00:09Z"
guardianId: "technology/2026/feb/26/chatgpt-health-fails-recognise-medical-emergencies"
---

A recent study found that ChatGPT Health often misses medical emergencies, giving dangerous advice. Researchers tested 60 real‑world scenarios and discovered that over half the cases needing urgent care were mis‑triaged. The AI also failed to flag suicidal thoughts in some tests. Experts warn that this could harm users and call for stronger safety rules and independent reviews.
